{
    "author": "'Joaquin Navajas'",
    "keywords": "",
    "journal": {
        "name": "",
        "year": "",
        "volume": "",
        "page": ""
    },
    "title": "Aggregated knowledge from a small number of  debates outperforms the wisdom of large crowds",
    "doi": "None",
    "abstract": "",
    "caption": {
        "figure 1": "Fig. 1 | Aggregating debates and the wisdom of crowds. a, A live crowd (N\u2009= \u20095,180) answered general knowledge questions in three stages. Left: initial  individual estimate (stage i1). Middle: consensus (stage c). Right: revised individual estimate (stage i2). In stage c, a moderator (white) recorded the  group\u2019s consensus estimate. b, Normalized error of the average of n individual answers (blue line for stage i1, red line for stage i2), and normalized error  of the average of m\u2009= \u2009n/5 collective estimates (black line, stage c). Error bars are s.e.m. c, Minimum number of collective decisions needed to significantly  (\u03b1\u2009= \u20090.01) outperform crowds of different sizes. At least two group estimates (from ten individuals) are needed to outperform the wisdom of five  independent individuals, and three estimates (from fifteen individuals) are needed to outperform the wisdom of ten independent estimates. For these crowd  sizes, the wisdom of crowds is more efficient than aggregating debates. However, averaging four collective decisions leads to estimates that are significantly  more accurate than the wisdom of crowds of any size.\u00a0The thin dashed line shows the number of groups corresponding to each crowd size   (five participants per group). When the solid line is below the dashed line, it indicates that averaging the group consensus outperforms averaging individuals.",
        "figure 2": "Fig. 2 | The effect of deliberation on bias and variance. a, Schematic of the process of deliberation in two groups (circles or triangles) answering the  question GOALS (see Supplementary Table\u00a01) across the three stages of the experiment. Vertical dashed lines show the mean of each group. The range of  opinions within each group decreased going from stage i1 to i2 (dotted black lines). The range of the average opinions (distance between vertical dashed  lines) increased after deliberation. b, Consensus decisions (grey bar) were less biased than the simple average of initial estimates in the group (blue bar).  Bars show mean bias (signed error) and s.e.m across m\u2009= \u2009280 groups. c, Revised estimates (obtained in stage i2) were closer to the consensus decision  (grey bar) than to the average of initial estimates (blue bar). Bars show mean distance and s.e.m (n\u2009= \u20091,400). d, Individuals conformed to the group  consensus. Deliberation decreased the diversity of opinions within groups. Bars show variance within groups (mean\u2009\u00b1 \u2009s.e.m. across m\u2009= \u2009280 groups) before  (blue bar) and after (red bar) deliberation. e, Deliberation led to polarization of opinion and pulled groups to wider extremes in the opinion space. This  process increased the diversity of opinions between different groups. The between-groups variance is obtained by taking the mean estimate of\u00a0each group  and computing the variance of this distribution across all groups (m\u2009= \u2009280). The inset shows the distribution of mean estimates before (blue) and after  (red) deliberation. Bars show variance between groups. f, We aggregated the individual estimates in two different ways: either by sampling participants all  from the same groups (within-groups condition) or by sampling each participant from a different interacting group (between-groups condition). The insets  sketch these two conditions; participants shaded by the same colour were averaged together. The y axis shows the normalized error of the average of n  individual answers at stage i2 for the within-groups (solid line) and the between-groups (dashed line) conditions. Sampling participants who interacted   in different debates leads to more accurate estimates.",
        "figure 3": "Fig. 3 | The superior wisdom of deliberative crowds. a, Collective accuracy in the absence of deliberation. Error reduction between averaging n revised  estimates compared with averaging n initial estimates, expressed as percentage decrease. The green line shows the mean error reduction (over N\u2009= \u20091,000  random subsamples) in the discussed questions and the grey line shows the same for the questions that remains undiscussed. Error bars depict s.e.m.   b, Simple aggregation rules fail to explain the accuracy of deliberative crowds. Normalized error of averaging N\u2009=\u2009100 randomly chosen collective decisions  (black bar) versus averaging simulated estimates produced by seven simple aggregation rules (blue bars). Aggregation rules: (1) resistance to social  influence, (2) confidence-weighted average, (3) expert rule, (4) median, (5) soft median, (6) mean, (7) robust average. See Methods for details about  these rules.\u00a0Error bars depict s.e.m. c, We tested whether four consensus choices could consistently and reliably outperform the wisdom of crowds.  Aggregating four random consensus estimates collected in the lab (experiment 2) was more accurate than aggregating all 5,180 individual estimates from  the crowd (experiment 1). The y axis shows error in normalized units (see Methods) and the error bar depicts s.e.m."
    },
    "reference": null
}